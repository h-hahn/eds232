---
title: "Lab4_Demo"
author: "Hope Hahn"
date: "2024-01-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)     # for data wrangling
library(ggplot2)   # for awesome plotting
library(rsample)   # for data splitting
library(recipes)   # data preprocessing
library(caret)     # for logistic regression modeling
```
Let's explore how employee income and overtime hours worked affect likelihood of employee attrition.  Any predictions?

```{r}
#
data("attrition", package = "modeldata")

df <- attrition %>% mutate_if(is.ordered, factor, ordered = FALSE)

# Create training (70%) and test (30%) sets for the 
# rsample::attrition data.
set.seed(123)  # for reproducibility 
churn_split <- initial_split(df, prop = 0.7)
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
```

Let's set up set up our recipes now for preprocessing. 
```{r recipe}
#specify and prep recipe
churn_rec <- recipe(Attrition ~ ., data = churn_train) %>% 
  step_integer(Attrition, zero_based = TRUE) %>% # this is turning it into numeric variable
  prep(churn_train) # prepping is not as important because we are not estimating parameters of the data. prepping estimates parameters

#bake recipe with training data
churn_baked_train <- bake(churn_rec, new_data = churn_train)
```

```{r specify_models_glm}
#MonthlyIncome
model_inc <- glm(data = churn_baked_train, Attrition ~ MonthlyIncome, family = "binomial")
  
#OverTime
model_time <- glm(data = churn_baked_train, Attrition ~ OverTime, family = "binomial")
```


```{r tidy_model_objs}
tidy(model_inc)
tidy(model_time)
```

```{r exp_coefs}
#exponentiate the coefficients from model objects for interpretation. Gives us changes in odds of attrition
exp(coef(model_inc))

# odds of employee attriting increases multiplicatively by 0.9998 by every dollar they make per month (lower than one so likelihood of them leaving decreases)

exp(coef(model_time))
```


```{r recode_attrition_test}
# baking is encoding the variables (binary 0 and 1)
churn_baked_test <- bake(churn_rec, new_data = churn_test) 
```

```{r plot_income_attrition}
ggplot(churn_baked_test, aes(x = MonthlyIncome, y = Attrition)) +
  geom_point() +
  stat_smooth(method = "glm", 
              se = TRUE, 
              method.args = list(family = "binomial")) +
  theme_minimal()
```

We can add more predictors, creating a multiple logistic regression model

```{r mult_log_regression}
model_both <- glm(Attrition ~ MonthlyIncome + OverTime, family = "binomial", data = churn_train)

tidy(model_both)
```

```{r}
ggplot(churn_baked_test, aes(x = MonthlyIncome, y = Attrition, color = OverTime)) +
  geom_point(alpha = 0.3) +
  stat_smooth(method = "glm", se = FALSE, method.args = list(family = binomial)) +
  theme_minimal()
```

